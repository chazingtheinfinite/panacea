{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichelet Allocation on Clinical Notes\n",
    "### Author: Kevin Dick\n",
    "\n",
    "This script builds the Latent Dirichelet Allocation (LDA) models on the MIMIC-III clinical notes. In order to manage the large number of clinical notes (over 2 Million) we choose to subsample these notes. We began with modestly sized training and test samples of 1000 clinical notes, however determined that a larger sample was necessary to appropriately capture the variation in this dataset.\n",
    "\n",
    "We selected a subsample size of 100,000 clinical notes to develop the Topic Model. We used perplexity analysis (described below) to select our hyperparameters.\n",
    "\n",
    "### The Date-Time Shift\n",
    "The dates and times have been shifted to preserve patient anonymity. The relative dates for a given patient are conserved, however the dates between patients or relative to the chronological ordering cannot be inferred. In order to appropriately generate the training and test sets, we need to perform a within-patient hold-out set. That is to say, we hold-out the data for the LAST visit to validate our methods. [MIMIC Date-Time Shifting](https://mimic.physionet.org/mimicdata/time/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import random\n",
    "import time\n",
    "\n",
    "# MIMIC-III Connection Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "# ----------------------------\n",
    "\n",
    "# Setup some Global Variables\n",
    "VERBOSE = True\n",
    "PICKLE_RICK = True\n",
    "\n",
    "\n",
    "# Set the database connection information\n",
    "sqluser = 'postgres'\n",
    "dbname = 'mimic'\n",
    "schema_name = 'mimiciii'\n",
    "\n",
    "# Connect to postgres with a copy of the MIMIC-III database\n",
    "con = psycopg2.connect(dbname=dbname, user=sqluser)\n",
    "\n",
    "# the below statement is prepended to queries to ensure they select from the right schema\n",
    "query_schema = 'set search_path to ' + schema_name + ';'\n",
    "\n",
    "if VERBOSE: print \"Setup Complete!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'a', u'about', u'above', u'after', u'again', u'against', u'all', u'am', u'an', u'and', u'any', u'are', u\"aren't\", u'as', u'at', u'be', u'because', u'been', u'before', u'being', u'below', u'between', u'both', u'but', u'by', u\"can't\", u'cannot', u'could', u\"couldn't\", u'did', u\"didn't\", u'do', u'does', u\"doesn't\", u'doing', u\"don't\", u'down', u'during', u'each', u'few', u'for', u'from', u'further', u'had', u\"hadn't\", u'has', u\"hasn't\", u'have', u\"haven't\", u'having', u'he', u\"he'd\", u\"he'll\", u\"he's\", u'her', u'here', u\"here's\", u'hers', u'herself', u'him', u'himself', u'his', u'how', u\"how's\", u'i', u\"i'd\", u\"i'll\", u\"i'm\", u\"i've\", u'if', u'in', u'into', u'is', u\"isn't\", u'it', u\"it's\", u'its', u'itself', u\"let's\", u'me', u'more', u'most', u\"mustn't\", u'my', u'myself', u'no', u'nor', u'not', u'of', u'off', u'on', u'once', u'only', u'or', u'other', u'ought', u'our', u'ours', u'ourselves', u'out', u'over', u'own', u'same', u\"shan't\", u'she', u\"she'd\", u\"she'll\", u\"she's\", u'should', u\"shouldn't\", u'so', u'some', u'such', u'than', u'that', u\"that's\", u'the', u'their', u'theirs', u'them', u'themselves', u'then', u'there', u\"there's\", u'these', u'they', u\"they'd\", u\"they'll\", u\"they're\", u\"they've\", u'this', u'those', u'through', u'to', u'too', u'under', u'until', u'up', u'very', u'was', u\"wasn't\", u'we', u\"we'd\", u\"we'll\", u\"we're\", u\"we've\", u'were', u\"weren't\", u'what', u\"what's\", u'when', u\"when's\", u'where', u\"where's\", u'which', u'while', u'who', u\"who's\", u'whom', u'why', u\"why's\", u'with', u\"won't\", u'would', u\"wouldn't\", u'you', u\"you'd\", u\"you'll\", u\"you're\", u\"you've\", u'your', u'yours', u'yourself', u'yourselves']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "if VERBOSE: print en_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the average number of clinical notes per patient...\n",
    "# This will help us determine the number of clinical notes to subsample when creating the LDA topic model!\n",
    "query = query_schema + \"\"\"\n",
    "SELECT subject_id, text\n",
    "FROM noteevents\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(query, con)\n",
    "total_notes = len(df)\n",
    "\n",
    "query = query_schema + \"\"\"\n",
    "SELECT subject_id, COUNT(subject_id) AS occurences\n",
    "FROM noteevents\n",
    "GROUP BY subject_id\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(query, con)\n",
    "avg_notes = df[\"occurences\"].mean()\n",
    "subsample_size = total_notes / avg_notes\n",
    "print 'Average number of Clinical Notes per Patient: ' + str(avg_notes)\n",
    "print 'Approximation of Minimum Subsample Size: ' + str(subsample_size)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Subsample Size: 100,000\n",
    "The average number of clinical notes per patient approximates the number of clinical notes. By setting the subsample size to 100,000 we can use ~2 clinical notes per patient which is useful when separating into training and testing subsamples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsampled Size of Clinical Notes: 100000\n"
     ]
    }
   ],
   "source": [
    "# === RANDOMLY SUBSAMPLE CLINICAL NOTES ===\n",
    "query = query_schema + \"\"\"\n",
    "SELECT subject_id, text\n",
    "FROM noteevents\n",
    "ORDER BY random()\n",
    "LIMIT 100000\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(query, con)\n",
    "\n",
    "print 'Subsampled Size of Clinical Notes: ' + str(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Size: 100000\n",
      "Length of Doc_set: 100000\n"
     ]
    }
   ],
   "source": [
    "# Compile the clinical notes into a list\n",
    "doc_set = []\n",
    "print 'DataFrame Size: ' + str(len(df))\n",
    "for i in range(0, len(df)):\n",
    "    doc_set.append(df.at[i,'text'])\n",
    "\n",
    "print 'Length of Doc_set: ' + str(len(doc_set))\n",
    "#print doc_set[2] # Look at the Second Entry to Validate\n",
    "#doc_set = [doc_a, doc_b, doc_c, doc_d, doc_e]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing of Clinical Notes\n",
    "Prior to dumping the files into the LDA, we need to perform a number of pre-processing steps.\n",
    "\n",
    "1) **Tokenization**: The text must be chopped into individual units (\"tokens\") for independent processing\n",
    "\n",
    "2) **Stop Word Removal**: Stop words are words which are filtered out before or after processing of natural language data and comprise the most common words in the English language.\n",
    "\n",
    "3) **Stemmitization**: The process of reducing inflected words to their word stem, base, or root form. (*e.g.* stemming --> stem)\n",
    "\n",
    "---\n",
    "\n",
    "An important additional step to be incorporated in future work is the removal of negated terms:\n",
    "[NegEx](https://github.com/mongoose54/negex/tree/master/negex.python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Tokens per Document:  268.47891\n",
      "Average Number of Stopped per Document: 211.37311\n",
      "Average Number of Stemmed per Document: 211.37311\n",
      "Number of Tokens over all Documents: 100000\n"
     ]
    }
   ],
   "source": [
    "# list for tokenized documents in loop\n",
    "texts = []\n",
    "\n",
    "# Variables to Track Summary Stats\n",
    "token_numbers = []\n",
    "stop_numbers  = []\n",
    "stem_numbers  = []\n",
    "\n",
    "# Now loop through document list\n",
    "for i in doc_set:\n",
    "    \n",
    "    # clean and tokenize document string\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    token_numbers.append(len(tokens))\n",
    "    \n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    stop_numbers.append(len(stopped_tokens))\n",
    "    \n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    stem_numbers.append(len(stemmed_tokens))\n",
    "    \n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n",
    "    \n",
    "# Get a sense of sizes:\n",
    "print 'Average Number of Tokens per Document:  ' + str(sum(token_numbers) / float(len(token_numbers)))\n",
    "print 'Average Number after Stop & Stem per Document: ' + str(sum(stem_numbers) / float(len(stem_numbers)))\n",
    "print 'Number of Tokens over all Documents: ' + str(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === OPTIONAL ===\n",
    "# Saving the list of tokens to file for relaoding later (previous computation time was several hours)\n",
    "f = open('./saved_tokens/token_list_100000_Subset.txt', 'w')\n",
    "for t in texts:\n",
    "    f.write(str(t) + '\\n')\n",
    "f.close()\n",
    "# === OPTIONAL ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the tokenized documents into a Key:Value Dictionary where Key = Id; Value = Term\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "#if VERBOSE: print dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Corpus Size :: 80000\n",
      "Testing Corpus Size :: 20000\n"
     ]
    }
   ],
   "source": [
    "# Convert tokenized documents into a document-term matrix\n",
    "# This is a matrix where the \n",
    "bow_corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "#if VERBOSE: print corpus\n",
    "    \n",
    "# === HERE WE ORGANIZE THE TRAIN AND TEST CORPI ===\n",
    "# split into train and test - random sample, but preserving order\n",
    "import random\n",
    "train_size = int(round(len(bow_corpus)*0.8))\n",
    "train_index = sorted(random.sample(xrange(len(bow_corpus)), train_size))\n",
    "test_index = sorted(set(xrange(len(bow_corpus)))-set(train_index))\n",
    "train_corpus = [bow_corpus[i] for i in train_index]\n",
    "test_corpus = [bow_corpus[j] for j in test_index]\n",
    "\n",
    "print 'Training Corpus Size :: ' + str(len(train_corpus))\n",
    "print 'Testing Corpus Size :: ' + str(len(test_corpus))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity Analysis\n",
    "\n",
    "With our subsampled set of clinical notes, we run perplexity analysis to determine the best number of topics to appropriately model our patients.\n",
    "\n",
    "The most common way to evaluate a probabilistic model is by training a the model on a corpus and measuring the log-likelihood of the held-out test set. The test set comprises a collection of unseen documents, in this case, the clinical notes of an independent patient. Given the naive subsampling approach, there is a small risk that the test corpus contains a clinical note pertaining to a patient with another note in the training set. This does not constitute duplication, however is a less stringent form of model generation and is suitable to our purpose given that the occureent is negligible. \n",
    "\n",
    "\n",
    "The test set is a collection of unseen documents, $w_{d}$.\n",
    "The model is described by the topic matrix $\\Phi$ and the hyper parameter $\\alpha$ for topic distribution of documents.\n",
    "The log-likelihood is evaluated as:\n",
    "\n",
    "$$ \\mathcal{L}(w) = log p(w|\\Phi, \\alpha) = \\sum_{d}{}log p(w_{d} | \\Phi, \\alpha) $$\n",
    "\n",
    "The higher the likelihood value, the better the model is considered. We can compare different topic models by considering their likelihood of unseen documents. This convention for measuring the suitability of a topic model is known as the *perplexity* of the held-out documents:\n",
    "\n",
    "$$ perplexity(w) = e^{-\\frac{\\mathcal{L(w)}}{||tokens||}}$$\n",
    "\n",
    "This is a decreasing function of the log-likelihood $\\mathcal{L}(w)$ over the unseen documents $w_{d}$ and a lower perplexity value is indicative of a better model since it indicates less **surprise** when evaluatating the unseen documents. A larger perplexity value indicates a larger degree of **surprise**.\n",
    "\n",
    "\n",
    "--- \n",
    "## Parameter Tuning over the Training and Test Set\n",
    "\n",
    "Here, we prepare the training and test set using the prepared bag-of-words corpus of all subsampled clinical notes. We will iterate over a parameter range from 10 to 300 in steps of 10, for 30 evaluations, each with 10 iterations. We will then plot the results and identify our hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning pass for number of topics :: 10\n",
      "Model Build Time: 133.514755964\n",
      "Topic Model Perplexity: -33543202.0988\n",
      "Model Test Time: 298.33893013\n",
      "Per-word Perplexity: 246.131589066\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 20\n",
      "Model Build Time: 291.37787199\n",
      "Topic Model Perplexity: -34743176.462\n",
      "Model Test Time: 385.997622967\n",
      "Per-word Perplexity: 299.715336158\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 30\n",
      "Model Build Time: 420.70893693\n",
      "Topic Model Perplexity: -35501227.175\n",
      "Model Test Time: 457.516501904\n",
      "Per-word Perplexity: 339.427886075\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 40\n",
      "Model Build Time: 517.701479912\n",
      "Topic Model Perplexity: -36200233.0277\n",
      "Model Test Time: 538.993718147\n",
      "Per-word Perplexity: 380.694838994\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 50\n",
      "Model Build Time: 621.62620616\n",
      "Topic Model Perplexity: -37491478.8429\n",
      "Model Test Time: 613.653211832\n",
      "Per-word Perplexity: 470.57082135\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 60\n",
      "Model Build Time: 777.958409071\n",
      "Topic Model Perplexity: -37746343.5091\n",
      "Model Test Time: 721.643485785\n",
      "Per-word Perplexity: 490.67431803\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 70\n",
      "Model Build Time: 908.623878956\n",
      "Topic Model Perplexity: -38569773.0109\n",
      "Model Test Time: 802.722398043\n",
      "Per-word Perplexity: 561.684560559\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 80\n",
      "Model Build Time: 1018.92259121\n",
      "Topic Model Perplexity: -39698584.1139\n",
      "Model Test Time: 877.634899139\n",
      "Per-word Perplexity: 676.022480697\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 90\n",
      "Model Build Time: 1198.84002495\n",
      "Topic Model Perplexity: -40767112.6643\n",
      "Model Test Time: 1035.88070703\n",
      "Per-word Perplexity: 805.624149991\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 100\n",
      "Model Build Time: 1335.027107\n",
      "Topic Model Perplexity: -41551805.9666\n",
      "Model Test Time: 998.200636148\n",
      "Per-word Perplexity: 916.368767605\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 110\n",
      "Model Build Time: 1312.98172617\n",
      "Topic Model Perplexity: -41811494.287\n",
      "Model Test Time: 978.363280773\n",
      "Per-word Perplexity: 956.274272907\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 120\n",
      "Model Build Time: 1374.20053816\n",
      "Topic Model Perplexity: -42965316.6052\n",
      "Model Test Time: 981.809237003\n",
      "Per-word Perplexity: 1155.67063565\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 130\n",
      "Model Build Time: 1458.30224395\n",
      "Topic Model Perplexity: -43507449.202\n",
      "Model Test Time: 1065.0791409\n",
      "Per-word Perplexity: 1263.22482026\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 140\n",
      "Model Build Time: 1488.88679314\n",
      "Topic Model Perplexity: -44654703.4051\n",
      "Model Test Time: 1060.92233205\n",
      "Per-word Perplexity: 1524.97962379\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 150\n",
      "Model Build Time: 1524.83907104\n",
      "Topic Model Perplexity: -45357531.7698\n",
      "Model Test Time: 1080.86812997\n",
      "Per-word Perplexity: 1711.45704314\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 160\n",
      "Model Build Time: 1616.74889588\n",
      "Topic Model Perplexity: -46377009.868\n",
      "Model Test Time: 1040.1533258\n",
      "Per-word Perplexity: 2023.20887233\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 170\n",
      "Model Build Time: 1652.1290431\n",
      "Topic Model Perplexity: -47207265.6188\n",
      "Model Test Time: 1127.88969994\n",
      "Per-word Perplexity: 2318.60355233\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 180\n",
      "Model Build Time: 1797.12983108\n",
      "Topic Model Perplexity: -47914792.1076\n",
      "Model Test Time: 1169.35271001\n",
      "Per-word Perplexity: 2604.13425585\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 190\n",
      "Model Build Time: 1900.78622389\n",
      "Topic Model Perplexity: -48496252.2959\n",
      "Model Test Time: 1182.48085785\n",
      "Per-word Perplexity: 2864.92631646\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 200\n",
      "Model Build Time: 1874.52148604\n",
      "Topic Model Perplexity: -49477197.1301\n",
      "Model Test Time: 1155.558218\n",
      "Per-word Perplexity: 3365.43560197\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 210\n",
      "Model Build Time: 1967.51072502\n",
      "Topic Model Perplexity: -49923162.2184\n",
      "Model Test Time: 1225.23355699\n",
      "Per-word Perplexity: 3621.03264699\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 220\n",
      "Model Build Time: 1998.81024694\n",
      "Topic Model Perplexity: -50063568.8383\n",
      "Model Test Time: 1237.86938906\n",
      "Per-word Perplexity: 3705.45458276\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 230\n",
      "Model Build Time: 2113.94548488\n",
      "Topic Model Perplexity: -51455923.0455\n",
      "Model Test Time: 1408.14095497\n",
      "Per-word Perplexity: 4656.90236363\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 240\n",
      "Model Build Time: 2115.36896086\n",
      "Topic Model Perplexity: -52453491.2481\n",
      "Model Test Time: 1277.73984003\n",
      "Per-word Perplexity: 5485.42115791\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 250\n",
      "Model Build Time: 2211.65231705\n",
      "Topic Model Perplexity: -52924679.2706\n",
      "Model Test Time: 1302.60832405\n",
      "Per-word Perplexity: 5926.51216399\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 260\n",
      "Model Build Time: 2428.0160048\n",
      "Topic Model Perplexity: -54705158.5371\n",
      "Model Test Time: 1377.72183514\n",
      "Per-word Perplexity: 7938.21355405\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 270\n",
      "Model Build Time: 2307.73148298\n",
      "Topic Model Perplexity: -54720974.6279\n",
      "Model Test Time: 1341.76574802\n",
      "Per-word Perplexity: 7958.84867057\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 280\n",
      "Model Build Time: 2640.42731285\n",
      "Topic Model Perplexity: -56090802.1748\n",
      "Model Test Time: 1501.40681815\n",
      "Per-word Perplexity: 9965.52183912\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 290\n",
      "Model Build Time: 2948.60020089\n",
      "Topic Model Perplexity: -55631172.9758\n",
      "Model Test Time: 1549.86992788\n",
      "Per-word Perplexity: 9241.33740936\n",
      "Saved Model to File!\n",
      "Beginning pass for number of topics :: 300\n",
      "Model Build Time: 2645.67352319\n",
      "Topic Model Perplexity: -56885224.7672\n",
      "Model Test Time: 1469.46023083\n",
      "Per-word Perplexity: 11353.5430662\n",
      "Saved Model to File!\n"
     ]
    }
   ],
   "source": [
    "# Prepare the Variables for looping...\n",
    "data_path = '/home/kevindick/MIMIC-III/code/latent_dirichelet_allocation/saved_LDA_models/'\n",
    "num_words = sum(cnt for document in test_corpus for _, cnt in document)\n",
    "parameter_range = range(10, 310, 10)\n",
    "results = {}\n",
    "\n",
    "for num_topics in parameter_range:\n",
    "    print \"Beginning pass for number of topics :: \" + str(num_topics)\n",
    "    start_time = time.time()\n",
    "    model = models.LdaMulticore(corpus=train_corpus, workers=None, id2word=dictionary, num_topics=num_topics, iterations=10)\n",
    "    print 'Model Build Time: ' + str(time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    perplexity = model.bound(test_corpus) # The Topic Model perplexity, not the per word perplexity\n",
    "    print \"Topic Model Perplexity: \" + str(perplexity)\n",
    "    print 'Model Test Time: ' + str(time.time() - start_time)\n",
    "    #grid.get(str(num_topics), []).append(perplexity)\n",
    "    #print grid[str(num_topics)]\n",
    "    \n",
    "    per_word_perplex = np.exp2(-perplexity / num_words)\n",
    "    print \"Per-word Perplexity: %s\" % per_word_perplex\n",
    "    #grid.get(num_topics).append(per_word_perplex)\n",
    "    model.save(data_path + 'ldaMulticore_NumTopics_' + str(num_topics) + '_training_corpus.lda')\n",
    "    print 'Saved Model to File!'\n",
    "\n",
    "    # Append to dictionary of results\n",
    "    results[\"numTopics\" + str(num_topics)] = [perplexity, per_word_perplex]\n",
    "\n",
    "# Generate the LDA model\n",
    "#ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=300, id2word = dictionary, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~chasingtheinfinite/25.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we plot the results...\n",
    "import cPickle as pickle\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "\n",
    "# Save the results\n",
    "#pickle.dump(results, open(data_path + \"perplexity_results.p\", \"wb\"))\n",
    "\n",
    "perplexies = []\n",
    "for num_topics in parameter_range:\n",
    "    perplexies.append(results[\"numTopics\" + str(num_topics)][1])\n",
    "    #print num_topics, '\\t',  results[\"numTopics\" + str(num_topics)]\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x = parameter_range,\n",
    "    y = perplexies,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'lines+markers'\n",
    ")    \n",
    "\n",
    "data = [trace]\n",
    "layout = dict(title = 'Perplexity Analysis Results',\n",
    "              yaxis = dict(title = 'Perplexity'),\n",
    "              xaxis = dict(title = 'Number of Topics'))\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='perplexities-plot')\n",
    "\n",
    "#df.to_pickle(data_path + 'gensim_multicore_topic_perplexity.df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Perplexity Analysis Thoughts\n",
    "\n",
    "From the resulting distribution of perplexity values the following conclusions are drawn:\n",
    "\n",
    "* **Minimum Perplexity Difficult to Define**: We anticipated using a minimum in the distribution as our operating point. No clear minium presented itself in this range and over this corpus. Small deviances of the general trend are seen at 220 and 270.\n",
    "\n",
    "* **Instability at Higher Topic Ranges**: Clearly a large amount of deviance from the original trend is percieved in the upper topic ranges. It is difficult to determine whether trends within these ranges account for meaningful representation of topics. Perhaps a higher resolution of model comparison might elucidate trends in these regions and establish a veritable \"dip\" indicative of a more appropriate topic value.\n",
    "\n",
    "* **Dip at 290**: The only point in the curve that resulted in a lower perplexity value than the previous iteration was at 290 topics.\n",
    "\n",
    "**Conclusion**: The operating threshold selected at this time is 270 given the small dip prior to the dramatic rise in perplexity and instability of higher topic ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Load the 270 Topic Model to move forward!\n",
    "NUM_TOPICS = 270\n",
    "model = model.load(data_path + 'ldaMulticore_NumTopics_' + str(NUM_TOPICS) + '_training_corpus.lda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring Topic Distributions of All Clinical Notes for our Patient Population\n",
    "\n",
    "### We select the operational point for the LDA, reload the model, and iterate over all notes\n",
    "\n",
    "We first segregate our patient population. We consider patients with at least two clinical notes to ensure they have a minimum number of notes to be represented in both the training and test sets.\n",
    "\n",
    "The results of each inference will be saved relative to the patient via **subject_id**. Once all notes have been processed, we need to average the topic distributions of all notes for a given patient to produce a single representative topic distribution. When possible, we withhold one note for each patient for our test set in the subsequent classification phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28365</td>\n",
       "      <td>2187-11-07</td>\n",
       "      <td>129055.0</td>\n",
       "      <td>Discharge Note.\\npt. admited with hypothermia,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28365</td>\n",
       "      <td>2187-11-07</td>\n",
       "      <td>129055.0</td>\n",
       "      <td>Nursing 0200-0700:\\n\\n47 year old male, Full C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28365</td>\n",
       "      <td>2192-06-20</td>\n",
       "      <td>102079.0</td>\n",
       "      <td>[**2192-6-20**] 4:05 PM\\n CTA CHEST W&amp;W/O C&amp;RE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28365</td>\n",
       "      <td>2192-06-20</td>\n",
       "      <td>102079.0</td>\n",
       "      <td>[**2192-6-20**] 4:04 PM\\n CT C-SPINE W/O CONTR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28365</td>\n",
       "      <td>2192-06-20</td>\n",
       "      <td>102079.0</td>\n",
       "      <td>[**2192-6-20**] 4:04 PM\\n CT HEAD W/O CONTRAST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28365</td>\n",
       "      <td>2192-06-20</td>\n",
       "      <td>102079.0</td>\n",
       "      <td>[**2192-6-20**] 3:04 PM\\n CHEST (PORTABLE AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28365</td>\n",
       "      <td>2190-01-07</td>\n",
       "      <td>121835.0</td>\n",
       "      <td>[**2190-1-7**] 3:15 PM\\n CHEST (PA &amp; LAT)     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28365</td>\n",
       "      <td>2190-01-05</td>\n",
       "      <td>121835.0</td>\n",
       "      <td>[**2190-1-5**] 6:51 PM\\n CHEST (PORTABLE AP)  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28365</td>\n",
       "      <td>2187-11-06</td>\n",
       "      <td>129055.0</td>\n",
       "      <td>[**2187-11-6**] 7:30 PM\\n CHEST (PA &amp; LAT)    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28365</td>\n",
       "      <td>2190-01-06</td>\n",
       "      <td>121835.0</td>\n",
       "      <td>TITLE:\\n   Chief Complaint:\\n   HPI:\\n   49 yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28365</td>\n",
       "      <td>2190-01-06</td>\n",
       "      <td>121835.0</td>\n",
       "      <td>This 49 Y/O male brought to [**Hospital1 54**]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28365</td>\n",
       "      <td>2190-01-06</td>\n",
       "      <td>121835.0</td>\n",
       "      <td>This 49 Y/O male brought to [**Hospital1 54**]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>28365</td>\n",
       "      <td>2190-01-06</td>\n",
       "      <td>121835.0</td>\n",
       "      <td>This 49 Y/O male brought to [**Hospital1 54**]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28365</td>\n",
       "      <td>2190-01-06</td>\n",
       "      <td>121835.0</td>\n",
       "      <td>This 49 Y/O male brought to [**Hospital1 54**]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28365</td>\n",
       "      <td>2190-01-06</td>\n",
       "      <td>121835.0</td>\n",
       "      <td>Chief Complaint:\\n   HPI:\\n   49yoM with h/o E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28365</td>\n",
       "      <td>2190-01-06</td>\n",
       "      <td>121835.0</td>\n",
       "      <td>Chief Complaint: hypotension\\n   I saw and exa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28365</td>\n",
       "      <td>2190-01-06</td>\n",
       "      <td>121835.0</td>\n",
       "      <td>Chief Complaint: hypotension\\n   I saw and exa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>28365</td>\n",
       "      <td>2190-01-06</td>\n",
       "      <td>121835.0</td>\n",
       "      <td>This 49 Y/O male brought to [**Hospital1 54**]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28365</td>\n",
       "      <td>2190-01-06</td>\n",
       "      <td>121835.0</td>\n",
       "      <td>Chief Complaint:\\n   HPI:\\n   49yoM with h/o E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28365</td>\n",
       "      <td>2190-01-06</td>\n",
       "      <td>121835.0</td>\n",
       "      <td>This 49 Y/O male brought to [**Hospital1 54**]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_id  chartdate   hadm_id  \\\n",
       "0        28365 2187-11-07  129055.0   \n",
       "1        28365 2187-11-07  129055.0   \n",
       "2        28365 2192-06-20  102079.0   \n",
       "3        28365 2192-06-20  102079.0   \n",
       "4        28365 2192-06-20  102079.0   \n",
       "5        28365 2192-06-20  102079.0   \n",
       "6        28365 2190-01-07  121835.0   \n",
       "7        28365 2190-01-05  121835.0   \n",
       "8        28365 2187-11-06  129055.0   \n",
       "9        28365 2190-01-06  121835.0   \n",
       "10       28365 2190-01-06  121835.0   \n",
       "11       28365 2190-01-06  121835.0   \n",
       "12       28365 2190-01-06  121835.0   \n",
       "13       28365 2190-01-06  121835.0   \n",
       "14       28365 2190-01-06  121835.0   \n",
       "15       28365 2190-01-06  121835.0   \n",
       "16       28365 2190-01-06  121835.0   \n",
       "17       28365 2190-01-06  121835.0   \n",
       "18       28365 2190-01-06  121835.0   \n",
       "19       28365 2190-01-06  121835.0   \n",
       "\n",
       "                                                 text  \n",
       "0   Discharge Note.\\npt. admited with hypothermia,...  \n",
       "1   Nursing 0200-0700:\\n\\n47 year old male, Full C...  \n",
       "2   [**2192-6-20**] 4:05 PM\\n CTA CHEST W&W/O C&RE...  \n",
       "3   [**2192-6-20**] 4:04 PM\\n CT C-SPINE W/O CONTR...  \n",
       "4   [**2192-6-20**] 4:04 PM\\n CT HEAD W/O CONTRAST...  \n",
       "5   [**2192-6-20**] 3:04 PM\\n CHEST (PORTABLE AP) ...  \n",
       "6   [**2190-1-7**] 3:15 PM\\n CHEST (PA & LAT)     ...  \n",
       "7   [**2190-1-5**] 6:51 PM\\n CHEST (PORTABLE AP)  ...  \n",
       "8   [**2187-11-6**] 7:30 PM\\n CHEST (PA & LAT)    ...  \n",
       "9   TITLE:\\n   Chief Complaint:\\n   HPI:\\n   49 yo...  \n",
       "10  This 49 Y/O male brought to [**Hospital1 54**]...  \n",
       "11  This 49 Y/O male brought to [**Hospital1 54**]...  \n",
       "12  This 49 Y/O male brought to [**Hospital1 54**]...  \n",
       "13  This 49 Y/O male brought to [**Hospital1 54**]...  \n",
       "14  Chief Complaint:\\n   HPI:\\n   49yoM with h/o E...  \n",
       "15  Chief Complaint: hypotension\\n   I saw and exa...  \n",
       "16  Chief Complaint: hypotension\\n   I saw and exa...  \n",
       "17  This 49 Y/O male brought to [**Hospital1 54**]...  \n",
       "18  Chief Complaint:\\n   HPI:\\n   49yoM with h/o E...  \n",
       "19  This 49 Y/O male brought to [**Hospital1 54**]...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make fancy query to pull the clinical notes of only patients with two or more admissions\n",
    "\n",
    "# Count number of times subject_id appears in the noteevents table (indicates number of unique notes)\n",
    "# \n",
    "query = query_schema + \"\"\"\n",
    "SELECT fusion_table.subject_id, fusion_table.chartdate, fusion_table.hadm_id, fusion_table.text\n",
    "FROM (\n",
    "    SELECT subject_id, num_visits\n",
    "    FROM (SELECT subject_id, COUNT(subject_id) AS num_visits\n",
    "        FROM admissions\n",
    "        GROUP BY subject_id) AS count_table\n",
    "    WHERE num_visits > 1) AS visit_table\n",
    "JOIN noteevents AS fusion_table ON visit_table.subject_id = fusion_table.subject_id \n",
    "\"\"\"\n",
    "df = pd.read_sql_query(query, con)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508276</th>\n",
       "      <td>17</td>\n",
       "      <td>2134-12-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal sinus rhythm. Tracing is within normal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508275</th>\n",
       "      <td>17</td>\n",
       "      <td>2134-12-27</td>\n",
       "      <td>194023.0</td>\n",
       "      <td>OP DAY MINIMALLY INVASIVE PFO REPAIR\\nNSR. NO ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508277</th>\n",
       "      <td>17</td>\n",
       "      <td>2134-12-27</td>\n",
       "      <td>194023.0</td>\n",
       "      <td>Sinus rhythm. Normal ECG. Since the previous t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508271</th>\n",
       "      <td>17</td>\n",
       "      <td>2134-12-28</td>\n",
       "      <td>194023.0</td>\n",
       "      <td>CSRU NURSING PROGRESS NOTE 0700-1900\\nCARDIAC-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508272</th>\n",
       "      <td>17</td>\n",
       "      <td>2134-12-28</td>\n",
       "      <td>194023.0</td>\n",
       "      <td>replaced K+ of 3.8 with 20 MEQ KCL IVPB\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508273</th>\n",
       "      <td>17</td>\n",
       "      <td>2134-12-28</td>\n",
       "      <td>194023.0</td>\n",
       "      <td>Neuro: A&amp;O X3,C/O incisional pain X1, medicate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508270</th>\n",
       "      <td>17</td>\n",
       "      <td>2134-12-29</td>\n",
       "      <td>194023.0</td>\n",
       "      <td>NEURO:  ALERT AND ORIENTED TO TIME, PLACE AND ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508297</th>\n",
       "      <td>17</td>\n",
       "      <td>2134-12-31</td>\n",
       "      <td>194023.0</td>\n",
       "      <td>Admission Date:  [**2134-12-27**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508278</th>\n",
       "      <td>17</td>\n",
       "      <td>2135-04-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sinus tachycardia. Otherwise, normal ECG. Sinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508279</th>\n",
       "      <td>17</td>\n",
       "      <td>2135-04-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sinus tachycardia. Otherwise, normal ECG. Sinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508280</th>\n",
       "      <td>17</td>\n",
       "      <td>2135-04-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sinus tachycardia. Normal ECG except for the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508282</th>\n",
       "      <td>17</td>\n",
       "      <td>2135-04-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sinus tachycardia. Normal ECG except for rate....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508283</th>\n",
       "      <td>17</td>\n",
       "      <td>2135-04-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sinus tachycardia\\nNo change from previous\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508293</th>\n",
       "      <td>17</td>\n",
       "      <td>2135-04-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PATIENT/TEST INFORMATION:\\nIndication: Pericar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508284</th>\n",
       "      <td>17</td>\n",
       "      <td>2135-05-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sinus rhythm. Normal ECG. Compared to the prev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508291</th>\n",
       "      <td>17</td>\n",
       "      <td>2135-05-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PATIENT/TEST INFORMATION:\\nIndication: Pericar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508268</th>\n",
       "      <td>17</td>\n",
       "      <td>2135-05-09</td>\n",
       "      <td>161087.0</td>\n",
       "      <td>CSRU Admission Note\\n\\nMrs. [**Known lastname ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508269</th>\n",
       "      <td>17</td>\n",
       "      <td>2135-05-09</td>\n",
       "      <td>161087.0</td>\n",
       "      <td>47yr female s/p pericardial window for tampona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508285</th>\n",
       "      <td>17</td>\n",
       "      <td>2135-05-09</td>\n",
       "      <td>161087.0</td>\n",
       "      <td>Regular narrow complex tachycardia - probably ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508286</th>\n",
       "      <td>17</td>\n",
       "      <td>2135-05-09</td>\n",
       "      <td>161087.0</td>\n",
       "      <td>Regular narrow complex tachycardia - probably ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subject_id  chartdate   hadm_id  \\\n",
       "508276          17 2134-12-22       NaN   \n",
       "508275          17 2134-12-27  194023.0   \n",
       "508277          17 2134-12-27  194023.0   \n",
       "508271          17 2134-12-28  194023.0   \n",
       "508272          17 2134-12-28  194023.0   \n",
       "508273          17 2134-12-28  194023.0   \n",
       "508270          17 2134-12-29  194023.0   \n",
       "508297          17 2134-12-31  194023.0   \n",
       "508278          17 2135-04-26       NaN   \n",
       "508279          17 2135-04-26       NaN   \n",
       "508280          17 2135-04-28       NaN   \n",
       "508282          17 2135-04-28       NaN   \n",
       "508283          17 2135-04-29       NaN   \n",
       "508293          17 2135-04-29       NaN   \n",
       "508284          17 2135-05-05       NaN   \n",
       "508291          17 2135-05-05       NaN   \n",
       "508268          17 2135-05-09  161087.0   \n",
       "508269          17 2135-05-09  161087.0   \n",
       "508285          17 2135-05-09  161087.0   \n",
       "508286          17 2135-05-09  161087.0   \n",
       "\n",
       "                                                     text  \n",
       "508276  Normal sinus rhythm. Tracing is within normal ...  \n",
       "508275  OP DAY MINIMALLY INVASIVE PFO REPAIR\\nNSR. NO ...  \n",
       "508277  Sinus rhythm. Normal ECG. Since the previous t...  \n",
       "508271  CSRU NURSING PROGRESS NOTE 0700-1900\\nCARDIAC-...  \n",
       "508272          replaced K+ of 3.8 with 20 MEQ KCL IVPB\\n  \n",
       "508273  Neuro: A&O X3,C/O incisional pain X1, medicate...  \n",
       "508270  NEURO:  ALERT AND ORIENTED TO TIME, PLACE AND ...  \n",
       "508297  Admission Date:  [**2134-12-27**]             ...  \n",
       "508278  Sinus tachycardia. Otherwise, normal ECG. Sinc...  \n",
       "508279  Sinus tachycardia. Otherwise, normal ECG. Sinc...  \n",
       "508280  Sinus tachycardia. Normal ECG except for the r...  \n",
       "508282  Sinus tachycardia. Normal ECG except for rate....  \n",
       "508283     Sinus tachycardia\\nNo change from previous\\n\\n  \n",
       "508293  PATIENT/TEST INFORMATION:\\nIndication: Pericar...  \n",
       "508284  Sinus rhythm. Normal ECG. Compared to the prev...  \n",
       "508291  PATIENT/TEST INFORMATION:\\nIndication: Pericar...  \n",
       "508268  CSRU Admission Note\\n\\nMrs. [**Known lastname ...  \n",
       "508269  47yr female s/p pericardial window for tampona...  \n",
       "508285  Regular narrow complex tachycardia - probably ...  \n",
       "508286  Regular narrow complex tachycardia - probably ...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the subject_id column to group together the date, and then internally sort the dates for each patient...\n",
    "# We will then post-process this further to ensure the data relevant to the last visit is excluded!\n",
    "sorted_df = df.sort_values(['subject_id', 'chartdate'], ascending=[True, True])\n",
    "sorted_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Design\n",
    "\n",
    "We have conserved the clinical notes of only those patients with two or more visits. Given the sorted dataframe of subject_id and datetimes relative to the clinical notes, we can appropriately divide this dataset into a training and test set on a per-patient basis. We use the *hadm_id* in the last record to allocate all notes related to that visit to the test set.\n",
    "\n",
    "---\n",
    "\n",
    "We  will now divide the dataset into a training and testing dataset. We differentitate the test set from the training set as the LAST record in the EHR. This  ensure that the clinical note is the most *future* record in the dataset. This same approach is employed accross this study. We use the latest temporal record based in *hadm_id* on a within-subject basis to ensure we predict the future diagnoses of that patient rather than performing simple recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Subjects: 7535\n",
      "Training Set Size: 739127\n",
      "Testing Set Size: 233855\n"
     ]
    }
   ],
   "source": [
    "# Generate the Training set by removing the last record from each subject within their group of notes\n",
    "train_df = pd.DataFrame(columns=['subject_id', 'chartdate', 'hadm_id', 'text'])\n",
    "test_df = pd.DataFrame(columns=['subject_id', 'chartdate', 'hadm_id', 'text'])\n",
    "\n",
    "# Create array of all unique subject_ids\n",
    "subjects = sorted_df.subject_id.unique()\n",
    "print 'Number of Subjects: ' + str(len(subjects))\n",
    "\n",
    "# Iterate over all subjects and get their grouped data in the sorted_df\n",
    "for subject in subjects:\n",
    "    group = sorted_df.loc[sorted_df['subject_id'] == subject]\n",
    "    \n",
    "    last_hadm = group.tail(1)['hadm_id']\n",
    "    \n",
    "    # List of items we want removed from the \n",
    "    to_remove = [last_hadm.item()]#, 'nan', 'NaN']\n",
    "        \n",
    "    not_last  = group.hadm_id.unique().tolist()\n",
    "    not_last  = [item for item in not_last if str(item) not in to_remove]\n",
    "    \n",
    "    # Put the data related to the LAST VISIT into the test set\n",
    "    test_df = pd.concat([test_df, group[group.hadm_id.isin(last_hadm)]])\n",
    "    \n",
    "    # Remaining get appended to the training set\n",
    "    #train_df = pd.concat([train_df, group.loc[(group['hadm_id'] != last_hadm)]])\n",
    "    train_df = pd.concat([train_df, group[group.hadm_id.isin(not_last)]])\n",
    "\n",
    "    \n",
    "print \"Training Set Size: \" + str(len(train_df))\n",
    "print \"Testing Set Size: \" + str(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PICKLE_RICK:\n",
    "    pickle.dump(train_df, open(data_path + \"train_df.p\", \"wb\"))\n",
    "    pickle.dump(test_df, open(data_path + \"test_df.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient Id   :: 17\n",
      "Patient HADM :: nan\n",
      "[]\n",
      "Note 0 :: Topic Compute Time = 0.0442798137665\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 194023.0\n",
      "[(14, 0.012824726650240037), (116, 0.70188837837473772), (134, 0.019360043611712931), (211, 0.1855474973422605), (241, 0.050430253867526385)]\n",
      "Note 1 :: Topic Compute Time = 0.0260610580444\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 194023.0\n",
      "[(251, 0.75092581786602886)]\n",
      "Note 2 :: Topic Compute Time = 0.00909900665283\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 194023.0\n",
      "[(14, 0.010761039994930197), (94, 0.029200275790082983), (117, 0.20038510267512843), (128, 0.11103096035874453), (132, 0.20490983783465841), (137, 0.21364957242226087), (142, 0.090140396543946871), (211, 0.1216139394675925)]\n",
      "Note 3 :: Topic Compute Time = 0.0219399929047\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 194023.0\n",
      "[(94, 0.4540388551536565), (116, 0.34744262632781858)]\n",
      "Note 4 :: Topic Compute Time = 0.00867795944214\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 194023.0\n",
      "[(14, 0.41408765006485787), (130, 0.14701499021372141), (178, 0.13317486344595864), (246, 0.27979657034953792)]\n",
      "Note 5 :: Topic Compute Time = 0.0151879787445\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 194023.0\n",
      "[(116, 0.15374239644815757), (130, 0.57310670137584885), (173, 0.12128980422603054), (178, 0.038318335722104593), (190, 0.048817764400928054), (226, 0.025870675130836466), (251, 0.012933515150077001)]\n",
      "Note 6 :: Topic Compute Time = 0.0491888523102\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 194023.0\n",
      "[(94, 0.19368161849431587), (130, 0.037247581878131528), (137, 0.056271291626271452), (173, 0.066295755279529786), (221, 0.43152772055163197), (249, 0.086069880488679265), (251, 0.11181713283803434)]\n",
      "Note 7 :: Topic Compute Time = 0.180436134338\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: nan\n",
      "[(251, 0.66790123456790307)]\n",
      "Note 8 :: Topic Compute Time = 0.0357649326324\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: nan\n",
      "[(251, 0.75092592592592755)]\n",
      "Note 9 :: Topic Compute Time = 0.0219669342041\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: nan\n",
      "[(178, 0.66790123456790484)]\n",
      "Note 10 :: Topic Compute Time = 0.0209529399872\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: nan\n",
      "[(251, 0.75074077811079476)]\n",
      "Note 11 :: Topic Compute Time = 0.0309131145477\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: nan\n",
      "[(143, 0.66790123456790573)]\n",
      "Note 12 :: Topic Compute Time = 0.0112528800964\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: nan\n",
      "[(130, 0.88930041099578472)]\n",
      "Note 13 :: Topic Compute Time = 0.0241601467133\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: nan\n",
      "[(178, 0.66790123322281747)]\n",
      "Note 14 :: Topic Compute Time = 0.00888919830322\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: nan\n",
      "[(98, 0.88928273991445006)]\n",
      "Note 15 :: Topic Compute Time = 0.0239419937134\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 161087.0\n",
      "[(14, 0.061388156457036984), (116, 0.40745530509821193), (120, 0.18172395496602592), (130, 0.29296191710041525), (214, 0.035128908776043383)]\n",
      "Note 16 :: Topic Compute Time = 0.0238409042358\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 161087.0\n",
      "[(178, 0.91697530864197963)]\n",
      "Note 17 :: Topic Compute Time = 0.00979089736938\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 161087.0\n",
      "[(116, 0.75092582625418069)]\n",
      "Note 18 :: Topic Compute Time = 0.0107860565186\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 161087.0\n",
      "[(211, 0.75092592592592755)]\n",
      "Note 19 :: Topic Compute Time = 0.0100209712982\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 161087.0\n",
      "[(178, 0.80074074074073698)]\n",
      "Note 20 :: Topic Compute Time = 0.0101940631866\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 161087.0\n",
      "[(121, 0.17608780132623925), (142, 0.22707447250363955), (211, 0.54189945456518429)]\n",
      "Note 21 :: Topic Compute Time = 0.0291938781738\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 161087.0\n",
      "[(211, 0.53713015298261868), (225, 0.36361058775812438)]\n",
      "Note 22 :: Topic Compute Time = 0.0311970710754\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 161087.0\n",
      "[(116, 0.33282630755303355), (132, 0.1698359591556588), (153, 0.46484167566262025)]\n",
      "Note 23 :: Topic Compute Time = 0.015419960022\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 161087.0\n",
      "[(190, 0.80074072498432391)]\n",
      "Note 24 :: Topic Compute Time = 0.0093240737915\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: 161087.0\n",
      "[(29, 0.12282216835101221), (128, 0.057857169269057422), (153, 0.23419830248821474), (211, 0.56813640842300306)]\n",
      "Note 25 :: Topic Compute Time = 0.0781090259552\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: nan\n",
      "[(14, 0.6679012345679104)]\n",
      "Note 26 :: Topic Compute Time = 0.00902199745178\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: nan\n",
      "[(153, 0.75092592592592944)]\n",
      "Note 27 :: Topic Compute Time = 0.00803709030151\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: nan\n",
      "[(116, 0.66790123456790662)]\n",
      "Note 28 :: Topic Compute Time = 0.00871396064758\n",
      "Patient Id   :: 17\n",
      "Patient HADM :: nan\n",
      "[(173, 0.87546296296296022)]\n",
      "Note 29 :: Topic Compute Time = 0.0223641395569\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: nan\n",
      "[(117, 0.80073725976350574)]\n",
      "Note 30 :: Topic Compute Time = 0.011528968811\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: nan\n",
      "[(71, 0.75092592592593188)]\n",
      "Note 31 :: Topic Compute Time = 0.0154421329498\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(62, 0.36658976864905168), (113, 0.43489171283242245)]\n",
      "Note 32 :: Topic Compute Time = 0.0146970748901\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(202, 0.92335442885019936)]\n",
      "Note 33 :: Topic Compute Time = 0.0173561573029\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(153, 0.83395061728394615)]\n",
      "Note 34 :: Topic Compute Time = 0.010312795639\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(130, 0.66790123456790607)]\n",
      "Note 35 :: Topic Compute Time = 0.00965690612793\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(20, 0.025838254505261768), (128, 0.010688472449143742), (137, 0.84679506790971037), (142, 0.059346016226710062), (169, 0.014818666892631926), (211, 0.030501394043613895)]\n",
      "Note 36 :: Topic Compute Time = 0.101755857468\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(14, 0.25620465987921803), (94, 0.023250801231453441), (116, 0.20441105056045158), (130, 0.076802083898655601), (132, 0.01197850884173921), (137, 0.29302618477931819), (153, 0.017177255950641412), (190, 0.10149831985254346)]\n",
      "Note 37 :: Topic Compute Time = 0.0974161624908\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(245, 0.55469137831762461), (246, 0.37913578217620375)]\n",
      "Note 38 :: Topic Compute Time = 0.0340969562531\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(211, 0.75092592592592833)]\n",
      "Note 39 :: Topic Compute Time = 0.0105299949646\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(116, 0.75092592592593044)]\n",
      "Note 40 :: Topic Compute Time = 0.0112919807434\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(14, 0.19443741034574172), (116, 0.11776645853037049), (132, 0.058360006839918488), (178, 0.015675239584337048), (190, 0.22885035516175406), (211, 0.21959303453662218), (251, 0.14366783402148775)]\n",
      "Note 41 :: Topic Compute Time = 0.024010181427\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(71, 0.068853087296718837), (134, 0.30413556449823392), (153, 0.49599563965273197), (211, 0.10022867151528102)]\n",
      "Note 42 :: Topic Compute Time = 0.0322399139404\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(117, 0.064872045925334465), (130, 0.33506466239298655), (137, 0.30832570747702026), (178, 0.099260270476625848), (246, 0.17782833639248272)]\n",
      "Note 43 :: Topic Compute Time = 0.0991208553314\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(39, 0.64517543902418029), (173, 0.050451769513964892), (245, 0.23373787082694342)]\n",
      "Note 44 :: Topic Compute Time = 0.0784709453583\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(116, 0.83395061728394448)]\n",
      "Note 45 :: Topic Compute Time = 0.0501179695129\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(153, 0.67346175674459385), (190, 0.12801972473688369)]\n",
      "Note 46 :: Topic Compute Time = 0.0216479301453\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(173, 0.87546296028341208)]\n",
      "Note 47 :: Topic Compute Time = 0.0340340137482\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(14, 0.057862578598853819), (97, 0.077293791766319425), (98, 0.32577882917484191), (132, 0.13751929077113578), (137, 0.031937973302269919), (187, 0.2557333363498851), (241, 0.09439271855520584)]\n",
      "Note 48 :: Topic Compute Time = 0.0555438995361\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(116, 0.18328765631895441), (128, 0.049290951610986324), (130, 0.0397657312697869), (132, 0.19811398770742544), (173, 0.058525753299273758), (184, 0.10943877055897042), (190, 0.24936281524271911), (211, 0.084168287503604847)]\n",
      "Note 49 :: Topic Compute Time = 0.0436041355133\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(187, 0.92336182336182693)]\n",
      "Note 50 :: Topic Compute Time = 0.0225789546967\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(14, 0.75092592592593366)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note 51 :: Topic Compute Time = 0.0135409832001\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(98, 0.23613182168205751), (116, 0.044143027973456081), (128, 0.014919982849893054), (130, 0.36948418455463705), (132, 0.0264935130667984), (173, 0.11796327193909999), (211, 0.11380485918952871), (241, 0.060209383893382096)]\n",
      "Note 52 :: Topic Compute Time = 0.083428144455\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(246, 0.94756335282651161)]\n",
      "Note 53 :: Topic Compute Time = 0.0417058467865\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(98, 0.93773148148148744)]\n",
      "Note 54 :: Topic Compute Time = 0.063383102417\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(89, 0.80074074074073254)]\n",
      "Note 55 :: Topic Compute Time = 0.0235199928284\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(104, 0.79028991501367296), (119, 0.085636010912247859)]\n",
      "Note 56 :: Topic Compute Time = 0.0136389732361\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(98, 0.72965632827890547), (119, 0.016718006607949844), (153, 0.22950642392072537)]\n",
      "Note 57 :: Topic Compute Time = 0.0262620449066\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(116, 0.92563268564536272), (246, 0.046007525992211827)]\n",
      "Note 58 :: Topic Compute Time = 0.0144321918488\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(211, 0.80074074074073864)]\n",
      "Note 59 :: Topic Compute Time = 0.0150978565216\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(178, 0.750925925817017)]\n",
      "Note 60 :: Topic Compute Time = 0.0100450515747\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(14, 0.28536225151472444), (94, 0.089842722928949945), (97, 0.24657363234453775), (137, 0.16197866965899035), (241, 0.19806714056239164)]\n",
      "Note 61 :: Topic Compute Time = 0.0224289894104\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(128, 0.80074069669017156)]\n",
      "Note 62 :: Topic Compute Time = 0.0179979801178\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(178, 0.8576719576719547)]\n",
      "Note 63 :: Topic Compute Time = 0.0123488903046\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(116, 0.83395061728394448)]\n",
      "Note 64 :: Topic Compute Time = 0.0131270885468\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(116, 0.75092589076542315)]\n",
      "Note 65 :: Topic Compute Time = 0.0109479427338\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(130, 0.85767195767195281)]\n",
      "Note 66 :: Topic Compute Time = 0.0174059867859\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(128, 0.29690676855181375), (211, 0.59280516560456964)]\n",
      "Note 67 :: Topic Compute Time = 0.0163731575012\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(162, 0.54893239415410366), (211, 0.25254908732737669)]\n",
      "Note 68 :: Topic Compute Time = 0.0113911628723\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(116, 0.26699824345640455), (208, 0.56756965777783508)]\n",
      "Note 69 :: Topic Compute Time = 0.0109350681305\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(14, 0.28829650671349905), (39, 0.033300783660219137), (137, 0.2632673849378539), (162, 0.21422177988232083), (241, 0.15526729380378407)]\n",
      "Note 70 :: Topic Compute Time = 0.0333030223846\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 109451.0\n",
      "[(2, 0.022977515220261424), (179, 0.033097048149262988), (184, 0.21482923766119547), (195, 0.13518506202102989), (237, 0.042916503089683943), (246, 0.34408866356799162), (255, 0.090232800314501996), (266, 0.097826824223817888)]\n",
      "Note 71 :: Topic Compute Time = 0.15967798233\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: nan\n",
      "[(24, 0.07178978601323921), (117, 0.030176285842814451), (153, 0.78815738493407683)]\n",
      "Note 72 :: Topic Compute Time = 0.0519731044769\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: nan\n",
      "[(132, 0.85767195767195248)]\n",
      "Note 73 :: Topic Compute Time = 0.0372519493103\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: nan\n",
      "[(130, 0.92336182336182926)]\n",
      "Note 74 :: Topic Compute Time = 0.03302693367\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: nan\n",
      "[(119, 0.8339506172839446)]\n",
      "Note 75 :: Topic Compute Time = 0.0154709815979\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: nan\n",
      "[(85, 0.033874476826296775), (162, 0.85583745733008854)]\n",
      "Note 76 :: Topic Compute Time = 0.0131878852844\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: nan\n",
      "[(132, 0.80074074074073431)]\n",
      "Note 77 :: Topic Compute Time = 0.00926804542542\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: nan\n",
      "[(2, 0.50185185185184789)]\n",
      "Note 78 :: Topic Compute Time = 0.0145971775055\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: nan\n",
      "[(119, 0.66785312159899723)]\n",
      "Note 79 :: Topic Compute Time = 0.0136229991913\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: nan\n",
      "[]\n",
      "Note 80 :: Topic Compute Time = 0.0124661922455\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(178, 0.75092592592592899)]\n",
      "Note 81 :: Topic Compute Time = 0.00945281982422\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(130, 0.20367643582483502), (132, 0.13549395576957887), (137, 0.56630681217533407), (211, 0.017430295876315186), (269, 0.048124093343843599)]\n",
      "Note 82 :: Topic Compute Time = 0.0724489688873\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(98, 0.07950547337593894), (128, 0.068421987534967463), (130, 0.17384187590857753), (132, 0.069356296343461674), (137, 0.41348175288011191), (142, 0.038126524459231786), (211, 0.072085566307975746), (225, 0.061878665024417315)]\n",
      "Note 83 :: Topic Compute Time = 0.114670038223\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(211, 0.83395061728394881)]\n",
      "Note 84 :: Topic Compute Time = 0.0501730442047\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(116, 0.35528825525781266), (126, 0.054941139857089392), (173, 0.12789094557366618), (187, 0.40653549696929292), (198, 0.013585048285720583)]\n",
      "Note 85 :: Topic Compute Time = 0.0562460422516\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(241, 0.85767195767195725)]\n",
      "Note 86 :: Topic Compute Time = 0.0226850509644\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(14, 0.10360806054718762), (128, 0.050012468799268892), (132, 0.75320224389635715), (153, 0.012293601763209242), (190, 0.031809550919907614)]\n",
      "Note 87 :: Topic Compute Time = 0.0192711353302\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(108, 0.020675799675762437), (116, 0.042358340209756068), (130, 0.076895872570375334), (137, 0.41004720131863781), (142, 0.42221024732221119), (169, 0.013772982016436586)]\n",
      "Note 88 :: Topic Compute Time = 0.0673260688782\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(116, 0.010371380149650488), (130, 0.2996690624964794), (132, 0.1617659604287372), (137, 0.26962801535200015), (173, 0.12920383509967007), (178, 0.099738005715254804), (211, 0.015708396842858251)]\n",
      "Note 89 :: Topic Compute Time = 0.108662128448\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(98, 0.90037031556851232)]\n",
      "Note 90 :: Topic Compute Time = 0.0684289932251\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(132, 0.66406356180156145), (173, 0.19413749639949196)]\n",
      "Note 91 :: Topic Compute Time = 0.0556030273438\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(132, 0.40513904956897318), (137, 0.41822655020559751), (142, 0.099573426128322567), (173, 0.049694718953063884)]\n",
      "Note 92 :: Topic Compute Time = 0.0457861423492\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(169, 0.93358024685303775)]\n",
      "Note 93 :: Topic Compute Time = 0.0281140804291\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(39, 0.10869096726967963), (116, 0.43863027059414655), (117, 0.13770534976521259), (130, 0.11988618210449882), (134, 0.11193673980148999), (137, 0.063195841938886027)]\n",
      "Note 94 :: Topic Compute Time = 0.0235989093781\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(14, 0.063508016437350434), (116, 0.41627209119895797), (130, 0.25988850531757596), (132, 0.033109482938411351), (178, 0.06968355126626237), (211, 0.026710060398580152), (225, 0.10707038819714394)]\n",
      "Note 95 :: Topic Compute Time = 0.0197570323944\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(130, 0.18101468802234197), (178, 0.67718635497556912)]\n",
      "Note 96 :: Topic Compute Time = 0.0207779407501\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(116, 0.87546296296295822)]\n",
      "Note 97 :: Topic Compute Time = 0.0170428752899\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(226, 0.8007393399087126)]\n",
      "Note 98 :: Topic Compute Time = 0.00959515571594\n",
      "Patient Id   :: 21\n",
      "Patient HADM :: 111970.0\n",
      "[(128, 0.056954051635950506), (130, 0.016105863490966824), (137, 0.4694064128529129), (142, 0.23364663848997039), (211, 0.15539179777249329), (225, 0.050046598441137402)]\n",
      "Note 99 :: Topic Compute Time = 0.0659132003784\n"
     ]
    }
   ],
   "source": [
    "# Now submit each of the training notes to be computed... \n",
    "# We leave out the testing notes since these will be used to create the representation of the patient in the testing phase\n",
    "topic_distributions = {}\n",
    "row = -1\n",
    "# Submit each clinical note to the model to obtain the corresponding topic distribution\n",
    "for note in train_df[\"text\"]:\n",
    "    start_time = time.time()\n",
    "    row += 1\n",
    "    texts = [] # Only want one note at a time so refresh for each note in the loop...\n",
    "    patient_id = train_df['subject_id'][row]\n",
    "    patient_hadm = train_df['hadm_id'][row]\n",
    "    \n",
    "    # Pre-Process\n",
    "    raw = note.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    texts.append(stemmed_tokens)\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    doc_bow = dictionary.doc2bow(text)\n",
    "    \n",
    "    # Now obtain the topic distribution!\n",
    "    doc_lda = model[doc_bow] \n",
    "    \n",
    "    # Save the results to a new df with the subject_id conserved...\n",
    "    topic_distributions[str(row)] = [patient_id, patient_hadm, doc_lda]\n",
    "    if VERBOSE and row < 100: # Only print the first couple to get an idea!\n",
    "        print \"Patient Id   :: \" + str(patient_id)\n",
    "        print \"Patient HADM :: \" + str(patient_hadm)\n",
    "        print doc_lda\n",
    "        print \"Note \" + str(row) + \" :: Topic Compute Time = \" + str(time.time() - start_time)\n",
    "\n",
    "pickle.dump(topic_distribution, open(data_path + \"train_df_topic_distributions.p\", \"wb\"))\n",
    "print \"Execution Complete!~\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
